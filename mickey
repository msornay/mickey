#!/usr/bin/env python3
"""Mickey - AI agent orchestrator."""

import argparse
import os
import random
import re
import subprocess
import sys
import threading
from pathlib import Path

AGENT_RULES = r"""# Agent Rules

You are a developer agent working inside a Docker sandbox.

## Workspace layout
- $WORKSPACE_DIR/ is synced to the host. NEVER modify files here directly — only write to merge-queue/.
- $WORKSPACE_DIR/repos/ contains git repos. NEVER write to this directory. Only use it as a clone source.
- ~/work/ is your local workspace. Clone repos here and do all work here.
- $WORKSPACE_DIR/merge-queue/<repo>/ is the merge queue. Patches here are ready for the human to apply.

## Your task
You receive a specific task as your prompt. Work on it directly.

## Starting work
0. Read $WORKSPACE_DIR/CLAUDE.md and $WORKSPACE_DIR/RULES.md for workspace-wide
   context and conventions. Then read the repo's own CLAUDE.md and RULES.md (if
   they exist) for project-specific context and rules. Follow all of these
   throughout your work.
1. Clone: git clone $WORKSPACE_DIR/repos/<repo> ~/work/<repo>
   Or update: cd ~/work/<repo> && git checkout main && git pull $WORKSPACE_DIR/repos/<repo> main
2. Apply pending patches from merge-queue: if $WORKSPACE_DIR/merge-queue/<repo>/ has .patch files, apply them to your local clone in sorted order:
   for patch in $(ls $WORKSPACE_DIR/merge-queue/<repo>/*.patch 2>/dev/null | sort); do git am "$patch"; done
   This ensures you work on top of other agents' pending changes, reducing conflicts.
3. Branch: cd ~/work/<repo> && git checkout -b <branch-name>
4. Author: git config user.name "$(hostname) [bot]" && git config user.email "$(hostname)+${ANTHROPIC_MODEL:-claude}@agent.local"

## Producing output
1. Run `make test` before producing a patch. Never submit with failing tests.
2. Squash to a single commit:
   TIMESTAMP=$(date +%Y%m%d-%H%M%S)
   cd ~/work/<repo> && git checkout -b squash-tmp main
   git merge --squash <branch> && git commit -m "<message>"
3. Produce the patch:
   mkdir -p $WORKSPACE_DIR/merge-queue/<repo>
   git format-patch ${TODO_FILE:+--add-header="X-Todo: $TODO_FILE"} --base=main main --stdout > $WORKSPACE_DIR/merge-queue/<repo>/${TIMESTAMP}-$(hostname)-<short-name>.patch
4. Verify: git checkout main && git am --check <patch-file>

## Deployment awareness
Deploying code is done by a human, not by agents. When your work involves deployment-relevant changes (configuration, infrastructure, environment variables, etc.):

1. Write clear documentation about the deployment steps needed.
2. If the repo has a `deploy` target in its Makefile, ensure your changes are compatible with it.
3. If the repo does NOT have a `deploy` target and your changes require deployment steps, create one as part of your patch. The `deploy` target should automate the configured deployment process.
4. Include deployment notes in your commit message when relevant.

## Rules
- NEVER write to $WORKSPACE_DIR/ except $WORKSPACE_DIR/merge-queue/
- NEVER modify, create, or delete files under $WORKSPACE_DIR/repos/
- NEVER delete files from $WORKSPACE_DIR/merge-queue/
- NEVER enter plan mode
- NEVER push to any remote or create pull requests
- Always run make test before producing a patch
- Make clean, atomic commits with good messages
"""

QA_RULES = r"""# QA Tester Rules

You are a QA tester, NOT a developer. Your job is to test software from a user's perspective.

## Workspace layout
- $WORKSPACE_DIR/repos/ contains git repos. You may ONLY read documentation files from here (README*, CLAUDE.md, RULES.md, docs/, Makefile help targets). Do NOT read source code.
- $WORKSPACE_DIR/todos/ is where you file bug reports.

## Your task
You receive a repo to test. Your job:

1. Read ONLY the documentation: README, CLAUDE.md, RULES.md, docs/, Makefile targets, CLI --help output.
   Do NOT read source code files (.py, .js, .ts, .rs, .swift, .java, .sh, etc.).

2. Clone the repo into ~/work/<repo> and follow the documented installation/setup instructions.
   Clean up when done: remove ~/work/<repo> so the sandbox stays clean for the next run.

3. Test every feature and workflow described in the documentation.
   Try edge cases, wrong inputs, missing prerequisites.

4. For each bug found, create a file in $WORKSPACE_DIR/todos/:
   Filename: bug-<repo>-<short-description>.txt
   Content:
     Repo: <repo>
     Bug: <short title>
     Steps to reproduce:
       1. ...
       2. ...
     Expected: ...
     Actual: ...

5. If everything works as documented, exit cleanly without creating any files.

## Rules
- NEVER read source code — only documentation and command output
- NEVER produce patches or write code
- NEVER modify anything under $WORKSPACE_DIR/repos/
- NEVER enter plan mode
- File bug reports ONLY for real bugs — not style preferences or feature requests
- Clean up after yourself — remove ~/work/<repo> when done
"""


def workspace() -> Path:
    return Path(os.environ.get("WORKSPACE_DIR", Path.home() / "src"))


# --- Task selection ---


def pick_task(ws: Path):
    """Pick a task: 10% rules audit, 90% random from todos + one QA entry.

    The 90% pool lists all real todo files plus one synthetic "QA" entry,
    then picks randomly.  This means:
      - Many todos → QA is rare (1/(N+1))
      - No todos   → QA is guaranteed
      - Few todos  → QA gets a fair share

    Returns (wip_path_or_None, prompt_text, agent_type).
    Returns (None, None, None) when no task is available.
    """
    repos_dir = ws / "repos"
    repos = []
    if repos_dir.is_dir():
        repos = [
            p.name
            for p in repos_dir.iterdir()
            if p.is_dir() and not p.name.startswith(".")
        ]

    roll = random.randint(1, 10)

    # 10% chance: rules audit (roll == 1)
    if roll == 1 and repos:
        repo = random.choice(repos)
        return (
            None,
            (
                f"Rules audit: clone $WORKSPACE_DIR/repos/{repo} "
                f"into ~/work/{repo}. "
                "Read $WORKSPACE_DIR/RULES.md and the repo's own "
                "RULES.md (if any). "
                "Verify the repo follows the rules documented there. "
                "For each violation found, create a todo file in "
                "$WORKSPACE_DIR/todos/ describing the issue. "
                "Exit cleanly if everything is in order."
            ),
            "qa",
        )

    # 90% chance: random pick from todos + one synthetic QA entry
    todos_dir = ws / "todos"
    todos = []
    if todos_dir.is_dir():
        todos = list(todos_dir.glob("*.txt"))

    # Build pool: real todos + one QA sentinel
    pool = list(todos)  # copy
    QA_SENTINEL = "QA"
    if repos:
        pool.append(QA_SENTINEL)

    if not pool:
        return None, None, None

    random.shuffle(pool)
    for pick in pool:
        if pick == QA_SENTINEL:
            repo = random.choice(repos)
            return (
                None,
                (
                    f"QA test $WORKSPACE_DIR/repos/{repo}. "
                    "Read only its documentation (README, CLAUDE.md, "
                    "RULES.md, docs/, Makefile targets, --help output). "
                    "Clone, install, and test every documented feature. "
                    "File bug reports in $WORKSPACE_DIR/todos/ for any "
                    "issues found. Clean up ~/work/ when done."
                ),
                "qa",
            )

        # Real todo file — mv is the concurrency lock
        wip_dir = ws / "wip"
        wip_dir.mkdir(exist_ok=True)
        dest = wip_dir / pick.name
        try:
            content = pick.read_text()
            pick.rename(dest)
        except OSError:
            continue  # another agent grabbed it, try next
        return dest, content, "developer"

    return None, None, None


def max_patches_per_repo(ws: Path) -> int:
    """Count .patch files per subdirectory in merge-queue/, return the max."""
    mq = ws / "merge-queue"
    if not mq.is_dir():
        return 0
    counts = {}
    for patch in mq.rglob("*.patch"):
        repo = patch.parent.name
        counts[repo] = counts.get(repo, 0) + 1
    return max(counts.values()) if counts else 0


def extract_subject(patch: Path) -> str:
    """Extract Subject line from a patch file."""
    try:
        with open(patch) as f:
            for line in f:
                if line.startswith("Subject:"):
                    return re.sub(r"^Subject:\s*\[PATCH[^\]]*\]\s*", "", line).strip()
    except OSError:
        pass
    return "(unknown)"


def extract_todo(patch: Path) -> str | None:
    """Extract X-Todo header from a patch file."""
    try:
        with open(patch) as f:
            for line in f:
                if line.strip() == "":
                    break  # end of headers
                if line.startswith("X-Todo:"):
                    return line.split(":", 1)[1].strip()
    except OSError:
        pass
    return None


# --- Agent management ---


def get_agents() -> list:
    """List available agent names from docker sandbox ls."""
    try:
        r = subprocess.run(
            ["docker", "sandbox", "ls"],
            capture_output=True,
            text=True,
            timeout=10,
        )
        lines = r.stdout.strip().splitlines()
        return [line.split()[0] for line in lines[1:] if line.strip()]
    except (subprocess.TimeoutExpired, FileNotFoundError, IndexError):
        return []


def start_agent(name, prompt, ws, model, agent_type="developer", todo_file=None):
    """Start an agent in a background thread. Returns the thread."""
    rules = QA_RULES if agent_type == "qa" else AGENT_RULES

    def run():
        cmd = [
            "docker",
            "sandbox",
            "run",
            name,
            "--",
            "--append-system-prompt",
            rules,
            "-p",
            prompt,
        ]
        env = dict(os.environ)
        if model:
            env["ANTHROPIC_MODEL"] = model
        if todo_file:
            env["TODO_FILE"] = todo_file
        try:
            proc = subprocess.Popen(
                cmd,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                env=env,
                start_new_session=True,
            )
            proc.wait()
            t.returncode = proc.returncode
        except Exception as e:
            print(f"[{name}] error: {e}", flush=True)
            t.returncode = 1

    t = threading.Thread(target=run, daemon=True, name=name)
    t.returncode = None
    t.start()
    return t


# --- Lock/unlock helpers ---


def lock(ws: Path):
    repos_dir = ws / "repos"
    if repos_dir.is_dir():
        subprocess.run(
            ["chmod", "-R", "a-w", str(repos_dir)],
            capture_output=True,
        )


def unlock(ws: Path):
    repos_dir = ws / "repos"
    if repos_dir.is_dir():
        subprocess.run(
            ["chmod", "-R", "u+w", str(repos_dir)],
            capture_output=True,
        )


# --- Commands ---


def cmd_hire(args):
    name = args.name
    subprocess.run(
        ["docker", "sandbox", "create", "--name", name, "claude", str(workspace())],
        check=True,
    )
    subprocess.run(["docker", "sandbox", "run", name], check=True)


def cmd_whip(args):
    ws = workspace()
    model = args.model

    if args.j is not None and args.j < 1:
        print("error: -j requires a positive integer.", file=sys.stderr)
        sys.exit(1)

    # Determine agents to use
    all_agents = get_agents()
    if not all_agents:
        print("no agents found. hire some first: mickey hire <name>")
        return

    if args.j is not None:
        if len(all_agents) < args.j:
            print(
                f"requested {args.j} agents but only {len(all_agents)} available.",
                file=sys.stderr,
            )
            sys.exit(1)
        agents = all_agents[: args.j]
    else:
        agents = all_agents

    import time

    threads = {}
    wip_files = {}  # agent_name -> wip_path
    last_am = time.monotonic()

    lock(ws)
    try:
        while True:
            patches = max_patches_per_repo(ws)
            stale = time.monotonic() - last_am > 900
            if patches >= 2 or (patches > 0 and stale):
                for t in threads.values():
                    t.join()
                threads.clear()
                unlock(ws)
                do_am(ws, push=True)
                lock(ws)
                last_am = time.monotonic()

            for n in agents:
                if n in threads and threads[n].is_alive():
                    continue
                # Agent finished — return its wip if no patch was produced
                if n in wip_files and wip_files[n]:
                    wip = wip_files.pop(n)
                    if wip.exists():
                        rc = threads[n].returncode if n in threads else None
                        dest = ws / "todos" / wip.name
                        wip.rename(dest)
                        if rc and rc != 0:
                            print(f"{n} died (exit {rc}), returned {wip.name} to todos/")
                        else:
                            print(f"returned {wip.name} to todos/")
                wip, prompt, agent_type = pick_task(ws)
                if prompt:
                    wip_files[n] = wip
                    print(f"sending {n} to work...")
                    threads[n] = start_agent(
                        n,
                        prompt,
                        ws,
                        model,
                        agent_type,
                        todo_file=wip.name if wip else None,
                    )

            time.sleep(25)
    finally:
        unlock(ws)


def cmd_sh(args):
    os.execvp("docker", ["docker", "sandbox", "exec", "-it", args.name, "bash"])


def cmd_ls(args):
    subprocess.run(["docker", "sandbox", "ls"])


def cmd_fire(args):
    subprocess.run(["docker", "sandbox", "rm", args.name], check=True)


def do_am(ws: Path, push: bool = False):
    """Apply patches from merge-queue/. Used by cmd_am and whip."""
    mq = ws / "merge-queue"
    patches = sorted(mq.rglob("*.patch"))
    if not patches:
        print("no patches in merge-queue/.")
        return

    applied_repos = set()
    for patch in patches:
        repo = patch.parent.name
        target = ws / "repos" / repo
        if not (target / ".git").is_dir():
            print(f"warning: {target} is not a git repo, skipping.")
            continue
        subject = extract_subject(patch)
        print(f"applying {patch.name} to {repo}...")
        result = subprocess.run(
            ["git", "am", str(patch)],
            cwd=target,
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            subprocess.run(
                ["git", "am", "--abort"],
                cwd=target,
                capture_output=True,
            )
            # Create a fix todo with the patch content
            todos_dir = ws / "todos"
            todos_dir.mkdir(exist_ok=True)
            fix_name = f"fix-{patch.stem}.txt"
            patch_content = patch.read_text()
            (todos_dir / fix_name).write_text(
                f"Repo: {repo}\n"
                f"The following patch did not apply cleanly. "
                f"Apply this fix to the current main.\n\n"
                f"{patch_content}"
            )
            patch.unlink()
            print(f"failed. created todos/{fix_name}")
            continue
        # Clean the wip file linked to this patch
        todo_name = extract_todo(patch)
        if todo_name:
            wip_file = ws / "wip" / todo_name
            if wip_file.exists():
                wip_file.unlink()
        applied_repos.add(repo)
        patch.unlink()
        # Clean empty dirs
        try:
            patch.parent.rmdir()
        except OSError:
            pass

    if push:
        for repo in sorted(applied_repos):
            print(f"pushing {repo}...")
            r = subprocess.run(
                ["git", "push"],
                cwd=ws / "repos" / repo,
                capture_output=True,
                text=True,
            )
            if r.returncode != 0:
                print(f"push failed for {repo}: {r.stderr.strip()}")

    print("done.")


def cmd_am(args):
    ws = workspace()
    do_am(ws, push=args.push)


def cmd_status(args):
    ws = workspace()

    try:
        subprocess.run(["docker", "sandbox", "ls"], timeout=10)
    except (subprocess.TimeoutExpired, FileNotFoundError):
        print("  (docker not available)")
    print()

    todos_dir = ws / "todos"
    todo_found = False
    if todos_dir.is_dir():
        for f in sorted(todos_dir.glob("*.txt")):
            todo_found = True
            first_line = f.read_text().strip().split("\n")[0]
            print(f"  {f.name}: {first_line}")
    if not todo_found:
        print("  (none)")
    print()

    wip_dir = ws / "wip"
    wip_found = False
    if wip_dir.is_dir():
        for f in sorted(wip_dir.glob("*.txt")):
            wip_found = True
            first_line = f.read_text().strip().split("\n")[0]
            print(f"  {f.name}: {first_line}")
        # Also check for old .wip files
        for f in sorted(wip_dir.glob("*.wip")):
            wip_found = True
            print(f"  {f.read_text().strip()}")
    if not wip_found:
        print("  (none)")
    print()

    mq = ws / "merge-queue"
    patch_found = False
    if mq.is_dir():
        for repo_dir in sorted(mq.iterdir()):
            if not repo_dir.is_dir():
                continue
            for patch in sorted(repo_dir.glob("*.patch")):
                patch_found = True
                subject = extract_subject(patch)
                print(f"  {repo_dir.name}: {subject}")
    if not patch_found:
        print("  (none)")


def cmd_reset(args):
    ws = workspace()
    wip_dir = ws / "wip"
    mq_dir = ws / "merge-queue"

    def count_files(d):
        if not d.is_dir():
            return 0
        return sum(1 for f in d.rglob("*") if f.is_file() and f.name != ".DS_Store")

    wip_count = count_files(wip_dir)
    mq_count = count_files(mq_dir)

    todos_dir = ws / "todos"

    print("this will:")
    print(f"  move {wip_count} file(s) from {wip_dir} back to {todos_dir}")
    print(f"  delete {mq_count} file(s) in {mq_dir}")
    answer = input("continue? [y/N] ")
    if answer.strip().lower() != "y":
        print("aborted.")
        sys.exit(1)

    if wip_dir.is_dir():
        todos_dir.mkdir(exist_ok=True)
        for f in wip_dir.iterdir():
            if f.is_file() and f.name != ".DS_Store":
                f.rename(todos_dir / f.name)

    if mq_dir.is_dir():
        for f in mq_dir.rglob("*"):
            if f.is_file() and f.name != ".DS_Store":
                f.unlink()
        # Clean empty subdirs
        for d in sorted(mq_dir.rglob("*"), reverse=True):
            if d.is_dir():
                try:
                    d.rmdir()
                except OSError:
                    pass

    print("done.")


def main():
    parser = argparse.ArgumentParser(
        prog="mickey",
        description="AI agent orchestrator",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""\
Commands:
  hire  <name>                             Create agent (interactive)
  whip  [--model <m>] [-j N]              Send agents to work
  sh    <name>                             Shell into agent
  ls                                       List agents
  fire  <name>                             Remove agent
  am    [--push]                           Apply patches from merge-queue/
  status                                   Show todos, wip, queued patches
  reset                                    Clear wip/ and merge-queue/
""",
    )
    sub = parser.add_subparsers(dest="command")

    p_hire = sub.add_parser("hire", help="Create agent")
    p_hire.add_argument("name")
    p_hire.set_defaults(func=cmd_hire)

    p_whip = sub.add_parser("whip", help="Send agents to work")
    p_whip.add_argument("--model", default=None)
    p_whip.add_argument("-j", type=int, default=None)
    p_whip.set_defaults(func=cmd_whip)

    p_sh = sub.add_parser("sh", help="Shell into agent")
    p_sh.add_argument("name")
    p_sh.set_defaults(func=cmd_sh)

    p_ls = sub.add_parser("ls", help="List agents")
    p_ls.set_defaults(func=cmd_ls)

    p_fire = sub.add_parser("fire", help="Remove agent")
    p_fire.add_argument("name")
    p_fire.set_defaults(func=cmd_fire)

    p_am = sub.add_parser("am", help="Apply patches from merge-queue/")
    p_am.add_argument("--push", action="store_true")
    p_am.set_defaults(func=cmd_am)

    p_status = sub.add_parser("status", help="Show status")
    p_status.set_defaults(func=cmd_status)

    p_reset = sub.add_parser("reset", help="Clear wip/ and merge-queue/")
    p_reset.set_defaults(func=cmd_reset)

    args = parser.parse_args()
    if not args.command:
        parser.print_help()
        sys.exit(1)

    args.func(args)


if __name__ == "__main__":
    main()
